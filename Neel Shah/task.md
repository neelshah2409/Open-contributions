# Supervised Machine Learning Algorithm
It is an algorithm that learns from labelled training data to help you predict outcomes for unforeseen data. In Supervised learning, you train the machine using data that is well “labelled.” It means some data is already tagged with correct answers. It can be compared to learning in the presence of a supervisor or a teacher

### Types of Supervised Machine Learning Algorithms

Following are the types of Supervised Machine Learning algorithms:

### Regression:

Regression technique predicts a single output value using training data.

**Example**: You can use regression to predict the house price from training data. The input variables will be locality, size of a house, etc.

#### Logistic Regression:

Logistic regression method used to estimate discrete values based on given a set of independent variables. It helps you to predicts the probability of occurrence of an event by fitting data to a logit function. Therefore, it is also known as logistic regression. As it predicts the probability, its output value lies between 0 and 1.

-------

## Unsupervised Learning
It is a machine learning technique in which the users do not need to supervise the model. Instead, it allows the model to work on its own to discover patterns and information that was previously undetected. It mainly deals with the unlabelled data.
-   Unsupervised machine learning helps you to finds all kind of unknown patterns in data.
-   Clustering and Association are two types of Unsupervised learning.
-   Four types of clustering methods are 1) Exclusive 2) Agglomerative 3) Overlapping 4) Probabilistic.
-   Important clustering types are: 1)Hierarchical clustering 2) K-means clustering 3) K-NN 4) Principal Component Analysis 5) Singular Value Decomposition 6) Independent Component Analysis.

------


### Types of Linear Regression

**Simple linear regression**  
1 dependent variable (interval or ratio), 1 independent variable (interval or ratio or dichotomous)

**Multiple linear regression**
1 dependent variable (interval or ratio) , 2+ independent variables (interval or ratio or dichotomous)

**Logistic regression**  
1 dependent variable (dichotomous), 2+ independent variable(s) (interval or ratio or dichotomous)

**Ordinal regression**  
1 dependent variable (ordinal), 1+ independent variable(s) (nominal or dichotomous)

**Multinomial regression**  
1 dependent variable (nominal), 1+ independent variable(s) (interval or ratio or dichotomous)



When selecting the model for the analysis, an important consideration is model fitting. Adding independent variables to a linear regression model will always increase the explained variance of the model. However, overfitting can occur by adding too many variables to the model, which reduces model generalizability. Statistically, if a model includes a large number of variables, some of the variables will be statistically significant due to chance alone.
